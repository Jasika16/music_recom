{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRuc9a_gwXAZ"
   },
   "source": [
    "This notebook is my implementation of the Neural Collabrative Filtering Recoomendation system. \n",
    "[NCF](https://arxiv.org/abs/1708.05031) models has other implementation, such as the [author's original implementation in theano](https://github.com/hexiangnan/neural_collaborative_filtering), the [offical tensorflow/keras version](https://github.com/tensorflow/models/tree/master/official/recommendation) and a [pytorch version](\n",
    "https://towardsdatascience.com/recotour-ii-neural-recommendation-algorithms-49733938d56e) with a [video](https://www.youtube.com/watch?v=O4lk9Lw7lS0) explaining it. In this notebook, I write the code so that it can be followed in a single google colab notebook with step by step instructuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J0sMrzLBxx6l"
   },
   "outputs": [],
   "source": [
    "# !kill -9 -1xw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuIb820ywcHY"
   },
   "source": [
    "### 1. Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "OVw8rAeju1VX",
    "outputId": "3f797c9e-bdcf-469d-f1f5-2e338c1c292b"
   },
   "outputs": [],
   "source": [
    "!curl -O 'http://files.grouplens.org/datasets/movielens/ml-100k.zip'\n",
    "!unzip ml-100k.zip\n",
    "!mkdir -p data\n",
    "\n",
    "!cp ml-100k/u.data data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y0G78vZGwjaC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8mfn4z2Bxbjv",
    "outputId": "8e40acd3-7eb5-4c3b-bf3a-11bdeae2cd2e"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0ERxv-wwga8"
   },
   "outputs": [],
   "source": [
    "input_file = 'data/u.data'\n",
    "headers = ['user_id', 'item_id', 'rating', 'timestamp']\n",
    "header_row = None\n",
    "ratings_df = pd.read_csv(input_file,\n",
    "                         sep='\\t',\n",
    "                         names=headers,\n",
    "                         header=header_row,\n",
    "                         dtype={\n",
    "                           'user_id': np.int32,\n",
    "                           'item_id': np.int32,\n",
    "                           'rating': np.float32,\n",
    "                           'timestamp': np.int32,\n",
    "                         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "9PaXMuQ4J3Jb",
    "outputId": "acc15297-01ea-498d-d3a9-6e6ba31a4e0c"
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MEVxRwPwepz"
   },
   "source": [
    "### 2. Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fe-BortnJ-1Y"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sIZrbRj_JuY5"
   },
   "outputs": [],
   "source": [
    "user_enc = LabelEncoder()\n",
    "product_enc = LabelEncoder()\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "ratings_df['user_id'] = user_enc.fit_transform(ratings_df['user_id'].values)\n",
    "ratings_df['item_id'] = product_enc.fit_transform(ratings_df['item_id'].values)\n",
    "ratings_df['rating'] = scaler.fit_transform(ratings_df['rating'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "-hD9wegNK3Ge",
    "outputId": "63ca919e-6416-4af5-f348-85326166ba42"
   },
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PkRecdunJtSe"
   },
   "outputs": [],
   "source": [
    "n_users = len(ratings_df['user_id'].unique())\n",
    "n_items = len(ratings_df['item_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5CWJZDNqynsN",
    "outputId": "7489e715-b5bc-4e94-a02b-b771ceadfb85"
   },
   "outputs": [],
   "source": [
    "print('number of unique user {}'.format(n_users))\n",
    "print('number of unique movie {}'.format(n_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6GXqmoMwLbNu",
    "outputId": "24bb200f-280f-4a2c-b616-29a51651465b"
   },
   "outputs": [],
   "source": [
    "ratings_df['user_id'].min() # make sure index start from 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnqzeLY5LlG9"
   },
   "outputs": [],
   "source": [
    "ratings = ratings_df[['user_id','item_id','rating']].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QlMekooy9_V"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tr_ratings, ts_ratings = train_test_split(ratings, test_size = 0.1)\n",
    "X_train = [[tr_ratings[:,0],tr_ratings[:,1]]]\n",
    "y_train = tr_ratings[:,2].reshape(-1,1)\n",
    "\n",
    "X_test = [[ts_ratings[:,0],ts_ratings[:,1]]]\n",
    "y_test = ts_ratings[:,2].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0jnV7Iwqz3sm"
   },
   "outputs": [],
   "source": [
    "## convert the rating matrix to a sparse matrix\n",
    "\n",
    "# from scipy.sparse import coo_matrix\n",
    "# u_tr, i_tr, r_tr = zip(*tr_ratings)\n",
    "# tr_sparse = coo_matrix((r_tr, (u_tr, i_tr)), shape=(n_users, n_items))\n",
    "\n",
    "# u_ts, i_ts, r_ts = zip(*ts_ratings)\n",
    "# test_sparse = coo_matrix((r_ts, (u_ts, i_ts)), shape=(n_users, n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b-mDJgz7OWil"
   },
   "source": [
    "### 3. build the model\n",
    "\n",
    "Note that the neural collaborative filtering (NCF) model is a combination of the generalized matrix factorization model(GMF) and the multilayer perception model(MLP). We can build each model first and then concatenate them. In fact, in the original paper, it shows that by pretraining each model then used the pretrained weight as initialiation point for the final model, you can reach a higher accuracy. \n",
    "![](https://drive.google.com/uc?id=1RqXBiGTCPFRpSkcTfpB7WgpYOXZyuXhx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "npnadXDHZRX_",
    "outputId": "665f3d6a-17a4-4ec3-e23e-8a7af9f7ce33"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHRqTpJaZxVv"
   },
   "source": [
    "**Part 1, build the GMF model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3D7tJLLOj8Q"
   },
   "outputs": [],
   "source": [
    "def build_GMF(embedding_dim, n_users, n_items):\n",
    "  # Input layers\n",
    "  user_input = tf.keras.layers.Input(shape=(1,)) # user\n",
    "  product_input = tf.keras.layers.Input(shape=(1,)) # movie\n",
    "  # Embedding layers\n",
    "  User_embedding = tf.keras.layers.Embedding(n_users, embedding_dim,\\\n",
    "                                             embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input)\n",
    "  Product_embedding = tf.keras.layers.Embedding(n_items, embedding_dim, \\\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input)\n",
    "  # Dot products\n",
    "  u = tf.keras.layers.Reshape((embedding_dim,))(User_embedding)\n",
    "  v = tf.keras.layers.Reshape((embedding_dim,))(Product_embedding)\n",
    "  s = tf.keras.layers.Dot(axes=1)([u, v])\n",
    "  model = tf.keras.Model(inputs=[user_input, product_input], outputs=s)\n",
    "  print(model.summary())\n",
    "  return(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "KxZvR4BDPEQP",
    "outputId": "b22beec4-3f64-4fd7-e316-ecded7bb5fb6"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "GMF_model = build_GMF(embedding_dim, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZrHGpDnNt9q"
   },
   "outputs": [],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "OluMrjFY36-_",
    "outputId": "b8ad519d-d00f-4162-e4a2-a35e71228ca2"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adagrad(learning_rate=0.5)  #Use Adagrad to get faster learning rate\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)  \n",
    "\n",
    "GMF_model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "history = GMF_model.fit(x=X_train, y=y_train,\n",
    "                  batch_size=64, epochs=500,\n",
    "                  validation_data= (X_test, y_test),\n",
    "                  callbacks=[checkpoint_callback, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCrOtpslOVoT"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_graph(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "l5kr2yX9Q3mz",
    "outputId": "bd48caac-63b4-4083-94c5-481ba11a1c78"
   },
   "outputs": [],
   "source": [
    "plot_graph(history, \"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nZr8cp8iRDbw"
   },
   "source": [
    "As we can see, we should use the model somewhere around the 10th epoches, we can load the saved weight from checkpoint file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "31athEBbRCgF",
    "outputId": "9ce3b505-d5a6-4bc4-8dd0-53a84472fd6d"
   },
   "outputs": [],
   "source": [
    "recovered_model = build_GMF(embedding_dim, n_users, n_items)\n",
    "recovered_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "recovered_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ySAF934lRjey"
   },
   "outputs": [],
   "source": [
    "prediction = recovered_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "XuGYwF_KRycv",
    "outputId": "d1e3bb06-7cc5-4640-dc90-dec27b4438ec"
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test,prediction,'o')\n",
    "plt.xlim(-0.5, 1.5)\n",
    "plt.ylim(-0.5, 1.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XP5iZ6bSTj5-"
   },
   "source": [
    "One can also add a bias layer, which represent the average score for each users, and the average score for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qzl6f1kTspS"
   },
   "outputs": [],
   "source": [
    "def build_bias(embedding_dim, n_users, n_items):\n",
    "    # Input layers\n",
    "    user_input = tf.keras.layers.Input(shape=(1,)) # user\n",
    "    product_input = tf.keras.layers.Input(shape=(1,)) # movie\n",
    "    # Embedding layers\n",
    "    User_embedding = tf.keras.layers.Embedding(n_users, embedding_dim,\\\n",
    "                                             embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input)\n",
    "\n",
    "    User_embedding_avg = tf.keras.layers.Embedding(n_users, 1,embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input)\n",
    "\n",
    "\n",
    "    Product_embedding = tf.keras.layers.Embedding(n_items, embedding_dim,\\\n",
    "                                             embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input)\n",
    "\n",
    "    Product_embedding_avg = tf.keras.layers.Embedding(n_items, 1,embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input)\n",
    "\n",
    "\n",
    "    # Dot products\n",
    "    u = tf.keras.layers.Reshape((embedding_dim,))(User_embedding)\n",
    "    v = tf.keras.layers.Reshape((embedding_dim,))(Product_embedding)\n",
    "    s = tf.keras.layers.Dot(axes=1)([u, v])\n",
    "\n",
    "    o = tf.keras.layers.Add()([s, User_embedding_avg, Product_embedding_avg])\n",
    "\n",
    "    model = tf.keras.Model(inputs=[user_input, product_input], outputs=o)\n",
    "    print(model.summary())\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEi4kL2bZ0V-"
   },
   "source": [
    "**Part 2, build the MLP model**\n",
    "\n",
    "We will be using two embedding layer (one for user and one for item), and 3 fully connective layers with size of [16,8,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hjb9nQ0lvBQ"
   },
   "outputs": [],
   "source": [
    "def build_MLP(embedding_dim, n_users, n_items):\n",
    "    # Input layers\n",
    "    user_input_mlp = tf.keras.layers.Input(shape=(1,)) # user\n",
    "    product_input_mlp = tf.keras.layers.Input(shape=(1,)) # movie\n",
    "    # Embedding layers\n",
    "    User_embedding_mlp = tf.keras.layers.Embedding(n_users, embedding_dim,\n",
    "                                                 embeddings_initializer= \"normal\",\n",
    "                                                  embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input_mlp)\n",
    "    Product_embedding_mlp = tf.keras.layers.Embedding(n_items, embedding_dim, \n",
    "                                                    embeddings_initializer= \"normal\",\n",
    "                                                    embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input_mlp)\n",
    "    # Concatenation of the two embedding\n",
    "    # u_mlp = tf.keras.layers.Flatten()(User_embedding_mlp)\n",
    "    # v_mlp = tf.keras.layers.Flatten()(Product_embedding_mlp)\n",
    "\n",
    "    u_mlp =tf.keras.layers.Reshape((embedding_dim,))(User_embedding_mlp)\n",
    "    v_mlp = tf.keras.layers.Reshape((embedding_dim,))(Product_embedding_mlp)\n",
    "\n",
    "    u_mlp = tf.keras.layers.Dropout(0.5)(u_mlp)\n",
    "    v_mlp = tf.keras.layers.Dropout(0.5)(v_mlp)\n",
    "\n",
    "    merged = tf.keras.layers.Concatenate(axis=1)([u_mlp, v_mlp])\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(64, activation='relu',\\\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(1e-6),\n",
    "                              activity_regularizer = tf.keras.regularizers.l2(1e-6))(merged)\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "    fcn = tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "\n",
    "    output_mlp = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=\"lecun_uniform\")(fcn)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[user_input_mlp, product_input_mlp], outputs=output_mlp)\n",
    "    print(model.summary())\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 663
    },
    "colab_type": "code",
    "id": "E_lBy1Dlr6O0",
    "outputId": "f29a5c34-66d7-4715-83e6-db3611415d7d"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "MLP_model = build_MLP(embedding_dim, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "colab_type": "code",
    "id": "ILOwnrq3uaFH",
    "outputId": "74ad6c66-c8f9-4f8c-e78c-a563b3c6135e"
   },
   "outputs": [],
   "source": [
    "# opt = tf.keras.optimizers.Adagrad(learning_rate=0.01)  #Use Adagrad to get faster learning rate\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)  \n",
    "\n",
    "MLP_model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "history = MLP_model.fit(x=X_train, y=y_train,\n",
    "                  batch_size=64, epochs=500,\n",
    "                  validation_data= (X_test, y_test),\n",
    "                  callbacks=[checkpoint_callback, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "jdH2aotTumu6",
    "outputId": "9a212304-3a73-411c-ca6b-9760abc69d68"
   },
   "outputs": [],
   "source": [
    "plot_graph(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "S2UfCCxFuqS4",
    "outputId": "91367329-fd9c-490e-ad16-7a20de78496f"
   },
   "outputs": [],
   "source": [
    "recovered_model = build_GMF(embedding_dim, n_users, n_items)\n",
    "recovered_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "recovered_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YBS2f36HusqY"
   },
   "outputs": [],
   "source": [
    "prediction = recovered_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "LKxxhgrSuwKa",
    "outputId": "305111eb-0fc0-4f24-e24a-db187ecfd4b1"
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test,prediction,'o')\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l-xSVBBSB4AR"
   },
   "source": [
    "**Part3 NCF: combining part1 and part2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wA_oEr6CAD9"
   },
   "outputs": [],
   "source": [
    "def build_NCF(embedding_dim, n_users, n_items):\n",
    "    user_input = tf.keras.layers.Input(shape=(1,)) # user\n",
    "    product_input = tf.keras.layers.Input(shape=(1,)) # movie\n",
    "\n",
    "    # Embedding of GMF\n",
    "    User_embedding_gmf = tf.keras.layers.Embedding(n_users, embedding_dim,\\\n",
    "                                             embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input)\n",
    "    Product_embedding_gmf = tf.keras.layers.Embedding(n_items, embedding_dim, \\\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input)\n",
    "\n",
    "    # Embedding of MLP\n",
    "    User_embedding_mlp = tf.keras.layers.Embedding(n_users, embedding_dim,\n",
    "                                            embeddings_initializer= \"normal\",\n",
    "                                            embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(user_input)\n",
    "    Product_embedding_mlp = tf.keras.layers.Embedding(n_items, embedding_dim, \n",
    "                                                    embeddings_initializer= \"normal\",\n",
    "                                                    embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(product_input)\n",
    "\n",
    "    # GMF: Matrix Multiplication\n",
    "    u = tf.keras.layers.Flatten()(User_embedding_gmf)\n",
    "    v = tf.keras.layers.Flatten()(Product_embedding_gmf)\n",
    "    output_gmf = tf.keras.layers.Dot(axes=1)([u, v])\n",
    "\n",
    "    # MLP: Concatenation of the two embedding\n",
    "    u_mlp = tf.keras.layers.Flatten()(User_embedding_mlp)\n",
    "    v_mlp = tf.keras.layers.Flatten()(Product_embedding_mlp)\n",
    "\n",
    "    u_mlp = tf.keras.layers.Dropout(0.5)(u_mlp)\n",
    "    v_mlp = tf.keras.layers.Dropout(0.5)(v_mlp)\n",
    "\n",
    "    merged_mlp = tf.keras.layers.Concatenate(axis=1)([u_mlp, v_mlp])\n",
    "\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(64, activation='relu',\\\n",
    "                              kernel_regularizer=tf.keras.regularizers.l2(1e-6),\n",
    "                              activity_regularizer = tf.keras.regularizers.l2(1e-6))(merged_mlp)\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(32, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "\n",
    "    fcn = tf.keras.layers.Dense(16, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "    output_mlp = tf.keras.layers.Dense(8, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-6))(fcn)\n",
    "\n",
    "    #merge two output\n",
    "    merged = tf.keras.layers.Concatenate(axis=1)([output_mlp, output_gmf])\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=\"lecun_uniform\")(merged)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[user_input, product_input], outputs=output)\n",
    "    print(model.summary())\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 901
    },
    "colab_type": "code",
    "id": "RLYFMESiGfWX",
    "outputId": "7a380b5d-9fe7-4d0f-e76d-128bbbbe1fb3"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 100\n",
    "NCF_model = build_NCF(embedding_dim, n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 972
    },
    "colab_type": "code",
    "id": "DSO23gcRGqmA",
    "outputId": "ad7e2b90-fac5-4494-d54a-7f043c407455"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adagrad(learning_rate=0.5)  #Use Adagrad to get faster learning rate\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.01)  \n",
    "\n",
    "NCF_model.compile(loss='mean_squared_error', optimizer=opt)\n",
    "\n",
    "history = NCF_model.fit(x=X_train, y=y_train,\n",
    "                  batch_size=64, epochs=500,\n",
    "                  validation_data= (X_test, y_test),\n",
    "                  callbacks=[checkpoint_callback, es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "f7cs4JZ9G8WG",
    "outputId": "4118b05e-4cbe-4b6a-8d05-c13817e5b085"
   },
   "outputs": [],
   "source": [
    "plot_graph(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "oZXV_-WOG-Ul",
    "outputId": "06900a69-90d8-4c5e-f64f-603a3b066e1b"
   },
   "outputs": [],
   "source": [
    "recovered_model = build_NCF(embedding_dim, n_users, n_items)\n",
    "recovered_model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "recovered_model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hEXv8NzHDWN"
   },
   "outputs": [],
   "source": [
    "prediction = recovered_model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "tIaHRlS1HFp5",
    "outputId": "96192dca-599b-4ac3-ea57-d58615829f51"
   },
   "outputs": [],
   "source": [
    "plt.plot(y_test,prediction,'o')\n",
    "plt.xlim(-1.5, 1.5)\n",
    "plt.ylim(-1.5, 1.5)\n",
    "plt.gca().set_aspect('equal', adjustable='box')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NCF",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
